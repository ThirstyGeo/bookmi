[
["single-missing-data-imputations.html", "Chapter 3 Single Missing data imputations 3.1 Complete cases analysis 3.2 Mean Imputation 3.3 Regression imputation 3.4 Bayesian Stochastic regression imputation", " Chapter 3 Single Missing data imputations 3.1 Complete cases analysis Complete case analysis (CCA) means that persons with a missing data point in a variable are excluded from the analysis. This procedure is still used a lot (Eekhout et al. 2012) but can have a large negative impact on the precision of the statistical test results. It also leads to an incorrect estimation of standard errors when the data is MCAR, MAR and MNAR (Eekhout et al. 2014). It is for that reason generally not recommended. It is however, the default procedure in a lot of statistical software packages as in SPSS. 3.2 Mean Imputation Assume that we are interested in the relationship between Pain and the Tampa scale variable. To get a first impression about this relationship we make a scatterplot. The scatterplots of the complete and incomplete datasets are displayed in (Figure 3.1 and 3.2): Figure 3.1: Relationship between the Tampa scale and Pain variables (green dots are observed and red dots are assumed to be missing data Figure 3.2: Relationship between the Tampa scale and Pain variable. Missing data are excluded The green dots represent the observed data and the red dots the missing data points. In practice, in your dataset you have the available points that are visualized in Figure 3.2. 3.2.1 Mean imputation in SPSS The easiest methods to do mean imputation are by using the Replace Missing Values procedure under Transform and by using the Linear Regression procedure. Replace Missing Values procedure You can find the Replace Missing Values dialog box via Transform -&gt; Replace Missing Values. A new window opens. Transport the Tampa scale variable to the New variable(s) window (Figure 3.3). The default imputation procedure is Mean imputation or called “Series mean”. Figure 3.3: Window for mean imputation of the Tampa scale variable. When you click on OK, a new variable is created in the dataset using the existing variable name followed by an underscore and a sequential number. The result is shown in Figure 3.4. Figure 3.4: Mean imputation of the Tampa scale variable with the Replace Missing Values procedure. The scatterplot between the Pain and the Tampa scale variable clearly shows the result of the mean imputation procedure, all imputed values are located at the mean value (Figure 3.5). Figure 3.5: Scatterplot between the Tampa scale and Pain variable, after the missing values of the Tampa scale variable have been replaced by the mean. Linear Regression Mean imputation in SPSS is also integrated in the Linear Regression menu via: Analyze -&gt; Regression -&gt; Linear -&gt; Options. In the Missing Values group you choose for Replace with mean (Figure 3.6). Figure 3.6: The option Replace with mean in the Linear Regression menu. You can also obtain the mean values by using Descriptive Statistics, and than replace the missing values by using the recode procedures: Transform -&gt; Recode into Same Variables. 3.2.2 Mean imputation in R You can do mean imputation by using the mice function in the mice package. library(foreign) # activate the foreign package to use the read.spss function dataset &lt;- read.spss(file=&quot;Backpain 50 missing.sav&quot;, to.data.frame=T) ## re-encoding from UTF-8 library(mice) # Activate the mice package to use the mice function imp_mean &lt;- mice(dataset, method=&quot;mean&quot;, m=1, maxit=1) ## ## iter imp variable ## 1 1 Tampascale You can extract the mean imputed dataset by using the complete function. complete(imp_mean) 3.3 Regression imputation 3.3.1 Regression imputation in SPSS Yoy do regression imputation in SPSS via the Missing Value Analysis procedures. There are two options for regression imputation, the Regression option and the EM (Expectation Maximization) option. The Regression option in SPSS has some flaws in the estimation of the regression parameters (see paper von Hippel 2004). Therefore, we use the EM algorithm. This algorithm is a likelihood-based procedure. This means that the most likely values of the regression coefficients are estimated given the data and subsequently used to impute the missing value. This EM procedure gives the same results as first performing a normal regression analysis in the dataset and subsequently estimate the missing values from the regression equation, after the missing values have been excluded. We will compare the EM and regression procedures below. 3.3.1.1 EM procedure Step 1, Choose: Analyze -&gt; Missing Value Analysis… In the main Missing Value Analysis dialog box, select the variable(s) that you want to use for the regression method and select EM in the Estimation group (Figure 3.7). Figure 3.7: EM Selection in the Missing Value Analysis window. Step 2 click Variables, to specify predicted and predictor variables. Place the Tampascale variable in the window of the Predicted variables and the Pain variable in the Predictor Variables window (Figure 3.8). Figure 3.8: Transfer of the Tampascale and Pain variables to the Predicted and Predictor Variables windows. Step 3 Click on Continue -&gt; EM and Choose for Normal in the Distribution group. Than thick Save completed data and give the dataset a name, for example “ImpTampa_EM” (Figure 3.9). Figure 3.9: Name of dataset to save the EM results in. Step 4 Click Continue -&gt; OK. The new dataset “ImpTampa_EM” will open in a new window in SPSS. In this dataset the imputed data of the Tampascale Variable together with the original data is stored (Figure 3.10, first 15 patients are shown). Adjust the Width and Decimals of the Tampa scale variable in the Variable View window to 4 and 3 respectively to get the same results as in Figure 3.13. Figure 3.10: Result of the EM procedure. Be aware that SPSS uses as default only quantitative variables to impute the missing values with the EM algorithm. If you want to include categorical variables in the imputation model as auxiliary variables, you have to define them as scale variables. 3.3.1.2 Normal Linear Regression We now compare the EM procedure with a two-step linear regression procedure. We first estimate the relationship between Pain and the Tampa scale variable in the dataset with linear regression after we have excluded the cases with missing values in the Tampa scale variable. Subsequently, we use the regression coefficients from this regression model to estimate the imputed values in the Tampa scale variable. Start by estimating the linear regression model with the Tampa scale variable as outcome variable (because we have to predict missing values in this variable) and use the Pain variable as the independent variable. To estimate the linear regression model, choose: Analyze -&gt; Regression -&gt; Linear Transfer the Tampa scale variable to the Dependent variable window and the Pain variable to the window of the Block 1 of 1 group. Then click OK. Figure 3.11: Linear regression analysis with the Tampa scale as the outcome and Pain as the independent variable. The following coefficients will be estimated (Figure 3.12). Figure 3.12: Result of the linear regression analysis. The linear regression model can be described as: Tampascale=32.005+1.410 ×Pain Now impute the missing values in the Tampa scale variable and compare them with the EM estimates. You see that the results are the same. Figure 3.13: Predictions of the missing Tampa scale values on basis of the regression model estimated in the dataset after the missing values were excluded. When you make a scatterplot of the imputations from the regression model you see that, as expected, the imputed values lie directly on the regression line (Figure 3.14). Figure 3.14: Relationship between the Tampa scale and the Pain variable. The Tampa scale variable is located on the y-axis. The imputed values of the Tampa scale variable (red dots) are located on the regression line that was used to generate the imputed values. The green dots are the observed data values. 3.3.2 Regression imputation in R You can aplly regression imputation in R with as method “norm.predict” in the mice function. The Pain variable is used to predict the missing values in the Tampa scale variable. library(foreign) dataset &lt;- read.spss(file=&quot;Mean imputation.sav&quot;, to.data.frame=T) ## re-encoding from UTF-8 dataset &lt;- dataset[, c(&quot;Pain&quot;, &quot;Tampascale&quot;)] imp.regress &lt;- mice(dataset, method=&quot;norm.predict&quot;, m=1, maxit=1) ## ## iter imp variable ## 1 1 Tampascale imp.regress$imp$Tampascale # Extract the imputed values ## 1 ## 2 40.46554 ## 6 41.87566 ## 9 34.82506 ## 14 40.46554 ## 21 39.05542 ## 25 39.05542 ## 27 44.69590 ## 31 46.10602 ## 35 40.46554 ## 37 43.28578 ## 44 33.41494 ## 49 34.82506 ## 50 43.28578 Expectantly, this gives comparable results as the regression imputation with SPSS above. The method “norm.predict” in the mice package fits a linear regression model in the dataset after the missing data is excluded and generates the imputed values for the Tampa scale variable by using the regression coefficients of the linear regression model. The same regression coefficients are used to predict the missing values in the Tampa scale variable as shown in Table 3.3. The completed dataset can be extracted by using the complete function in the mice package. 3.3.3 Stochastic regression imputation With Stochastic regression models imputation uncertainty is accounted for by adding extra error variance to the predicted values that are generated by the linear regression model. Stochastic regression can be activated in SPSS via the Missing Value Analysis and the Regression Estimation option. However, the Regression Estimation option generates incorrect regression coefficient estimates (von Hippel, 2004) and will therefore not further discussed. 3.3.4 Stochastic regression imputation in R You can apply stochastic regression imputation in R with the mice function. For this you use as method “norm.nob”. dataset &lt;- read.spss(file=&quot;Backpain 50 missing.sav&quot;, to.data.frame=T) ## re-encoding from UTF-8 dataset &lt;- dataset[, c(&quot;Pain&quot;, &quot;Tampascale&quot;)] imp_nob &lt;- mice(dataset, method=&quot;norm.nob&quot;, m=1, maxit=1) ## ## iter imp variable ## 1 1 Tampascale The completed dataset can be extracted by using the complete function in the mice package. 3.4 Bayesian Stochastic regression imputation The difference between the non-Bayesian imputation procedure that you applied above and Bayesian imputation is that with the latter method extra variation is added to the imputed values via the regression coefficients. The idea is used that there is not one true (population) regression coefficient but that the regression coefficient itself follows a (probability) distribution. This is in contrast to the frequentist idea, which assume that there is one true population parameter. In this case the regression coefficient (is reflected by the confidence interval). In this book (and most statistial books) the freuentist approach is used For more information about the theory of Bayesian statistics we refer to the books of Box and Tiao (1992), Enders (2012) and Gelman et al. (2004). 3.4.1 Bayesian Stochastic regression imputation in SPSS In SPSS Bayesian Stochastic regression imputation can be performed via the multiple imputation menu. To generate imputations for the Tampa scale variable, we use the Pain variable as the only predictor. Step 1 To start the imputation procedure, Go to Analyze -&gt; Multiple Imputation -&gt; Impute Missing Data Values. In the first window you define which variables are included in the imputation model. Transfer the Tampa scale and Pain variable to the Variables in Model window. Than set the number of imputed datasets to 1 under Imputations and give the dataset where the imputed values are stored under “Create a new dataset” a name. Here we give it the name “ImpStoch_Tampa” (Figure 3.15). Figure 3.15: The Variables window. Step 2 In the Methods window, choose under Imputation Method for customand then Fully conditional specification (MCMC). Set the Maximum iterations number at 50. This specifies the number of iterations as part of the FCS method (Figure 3.16). We further use the default settings. Figure 3.16: The Methods window. Step 3 In the constraints window (Figure 3.17) click on the Scan Data button and further use the default settings. Figure 3.17: Stochastic regression imputation Step 4 In the Output window we only use the default settings. Figure 3.18: The Output window. Step 5 Now click on OK button to start the imputation procedure The output dataset consists of the original data with missing data plus a set of cases with imputed values for each imputation. These imputed datasets are stacked under each other. The file also contains a new variable, Imputation_, which indicates the number of the imputed dataset (0 for original data and more than 0 for the imputed datasets). The variable Imputation_ is added to the dataset and the imputed values are marked yellow. Figure 3.19: Imputed dataset with the variable Imputation_ to distinguish the original and imputed datasets. Figure 3.20: Imputed dataset with the imputed values marked yellow. When we make a scatterplot of the Pain and the Tampascale variable (Figure 3.21) we see that there is more variation in the Tampascale variable, or you could say that the variation in the Tampascale variable is “repaired”. Figure 3.21: Scatterplot of the relationship between Tampascale and the Pain variable, including the imputed values for the Tampascale variable (red dots). The full Multiple Imputation procedure will be discussed in more detail in the next Chapter. 3.4.2 Bayesian Stochastic regression imputation in R The package mice also include a Bayesian stochastic regression imputation procedure. This method also accounts for imputation uncertainty, not only via the residuals (error variance), but also via the regression coefficients, which means that extra noise (or random error) is added to the regression coefficients. This imputation procedure is done by using the mice.impute.norm function. For the example to apply this method in R code 3.8 we use the same dataset as above with missing values in the Tampa scale variable and the pain variable as the only predictor variable for these missing values. dataset &lt;- read.spss(file=&quot;Backpain 50 missing.sav&quot;, to.data.frame=T) ## re-encoding from UTF-8 dataset &lt;- dataset[, c(&quot;Pain&quot;, &quot;Tampascale&quot;)] imp_b &lt;- mice(dataset, method=&quot;norm&quot;, m=1, maxit=1) ## ## iter imp variable ## 1 1 Tampascale imp_b$imp$Tampascale # Extract the imputed values ## 1 ## 2 41.44162 ## 6 42.15849 ## 9 32.22314 ## 14 40.47219 ## 21 38.30462 ## 25 38.73900 ## 27 43.06574 ## 31 45.49201 ## 35 40.41812 ## 37 46.10145 ## 44 32.07512 ## 49 31.42873 ## 50 47.74084 The completed dataset can be extracted by using the complete function in the mice package. Predictive Mean Matching: Predictive mean matching (PMM) is an imputation method that predicts values and subsequently selects observed values to be used to replace the missing values. It is the default imputation procedure in the mice package to impute missing data in continuous variables (Rubin, 1987, p. 168). The strength of this procedure is that missing data is replaced by data that is observed in the dataset and not replaced by unrealistic values (as negative body weight values). "]
]
