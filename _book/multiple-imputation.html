<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Applied Missing data analysis with SPSS and R(Studio)</title>
  <meta name="description" content="Applied Missing data analysis with SPSS and R(Studio)">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Applied Missing data analysis with SPSS and R(Studio)" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Applied Missing data analysis with SPSS and R(Studio)" />
  
  
  

<meta name="author" content="Martijn Heymans and Iris Eekhout">


<meta name="date" content="2018-10-20">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="single-missing-data-imputations.html">
<link rel="next" href="data-analysis-after-multiple-imputation.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Applied Missing Data Analysis</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="0.1" data-path="index.html"><a href="index.html#the-goal-of-this-manual"><i class="fa fa-check"></i><b>0.1</b> The goal of this Manual</a></li>
<li class="chapter" data-level="0.2" data-path="index.html"><a href="index.html#multiple-imputation-in-spss-and-r"><i class="fa fa-check"></i><b>0.2</b> Multiple Imputation in SPSS and R</a></li>
<li class="chapter" data-level="0.3" data-path="index.html"><a href="index.html#notation-and-annotation-in-this-manual"><i class="fa fa-check"></i><b>0.3</b> Notation and annotation in this manual</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="software-applications.html"><a href="software-applications.html"><i class="fa fa-check"></i><b>1</b> Software applications</a><ul>
<li class="chapter" data-level="1.1" data-path="software-applications.html"><a href="software-applications.html#spss-data-and-variable-view-windows"><i class="fa fa-check"></i><b>1.1</b> SPSS, Data and Variable View windows</a></li>
<li class="chapter" data-level="1.2" data-path="software-applications.html"><a href="software-applications.html#analyzing-data-in-spss"><i class="fa fa-check"></i><b>1.2</b> Analyzing data in SPSS</a></li>
<li class="chapter" data-level="1.3" data-path="software-applications.html"><a href="software-applications.html#data-transformations-in-spss"><i class="fa fa-check"></i><b>1.3</b> Data Transformations in SPSS</a></li>
<li class="chapter" data-level="1.4" data-path="software-applications.html"><a href="software-applications.html#the-output-window-in-spss"><i class="fa fa-check"></i><b>1.4</b> The Output window in SPSS</a></li>
<li class="chapter" data-level="1.5" data-path="software-applications.html"><a href="software-applications.html#the-syntax-editor-in-spss"><i class="fa fa-check"></i><b>1.5</b> The Syntax Editor in SPSS</a></li>
<li class="chapter" data-level="1.6" data-path="software-applications.html"><a href="software-applications.html#reading-and-saving-data-in-spss"><i class="fa fa-check"></i><b>1.6</b> Reading and saving data in SPSS</a></li>
<li class="chapter" data-level="1.7" data-path="software-applications.html"><a href="software-applications.html#r-and-rstudio"><i class="fa fa-check"></i><b>1.7</b> R and RStudio</a><ul>
<li class="chapter" data-level="1.7.1" data-path="software-applications.html"><a href="software-applications.html#the-role-of-the-console-window"><i class="fa fa-check"></i><b>1.7.1</b> The role of the Console Window</a></li>
<li class="chapter" data-level="1.7.2" data-path="software-applications.html"><a href="software-applications.html#r-assignments-and-objects"><i class="fa fa-check"></i><b>1.7.2</b> R assignments and objects</a></li>
<li class="chapter" data-level="1.7.3" data-path="software-applications.html"><a href="software-applications.html#vectors-matrices-lists-and-data-frames"><i class="fa fa-check"></i><b>1.7.3</b> Vectors, matrices, lists and data frames</a></li>
<li class="chapter" data-level="1.7.4" data-path="software-applications.html"><a href="software-applications.html#indexing-vectors-matrices-lists-and-data-frames"><i class="fa fa-check"></i><b>1.7.4</b> Indexing Vectors, Matrices, Lists and Data frames</a></li>
<li class="chapter" data-level="1.7.5" data-path="software-applications.html"><a href="software-applications.html#vectorized-calculation"><i class="fa fa-check"></i><b>1.7.5</b> Vectorized Calculation</a></li>
<li class="chapter" data-level="1.7.6" data-path="software-applications.html"><a href="software-applications.html#r-functions"><i class="fa fa-check"></i><b>1.7.6</b> R Functions</a></li>
<li class="chapter" data-level="1.7.7" data-path="software-applications.html"><a href="software-applications.html#the-help-function"><i class="fa fa-check"></i><b>1.7.7</b> The Help function</a></li>
<li class="chapter" data-level="1.7.8" data-path="software-applications.html"><a href="software-applications.html#working-with-script-files"><i class="fa fa-check"></i><b>1.7.8</b> Working with script files</a></li>
<li class="chapter" data-level="1.7.9" data-path="software-applications.html"><a href="software-applications.html#creating-a-working-directory"><i class="fa fa-check"></i><b>1.7.9</b> Creating a working directory</a></li>
<li class="chapter" data-level="1.7.10" data-path="software-applications.html"><a href="software-applications.html#reading-in-spss-data-in-rstudio"><i class="fa fa-check"></i><b>1.7.10</b> Reading in SPSS data in RStudio</a></li>
<li class="chapter" data-level="1.7.11" data-path="software-applications.html"><a href="software-applications.html#saving-and-reading-r-data-in-rstudio"><i class="fa fa-check"></i><b>1.7.11</b> Saving and Reading R data in RStudio</a></li>
<li class="chapter" data-level="1.7.12" data-path="software-applications.html"><a href="software-applications.html#reading-in-rstudio-data-into-spss"><i class="fa fa-check"></i><b>1.7.12</b> Reading in (R)Studio data into SPSS</a></li>
<li class="chapter" data-level="1.7.13" data-path="software-applications.html"><a href="software-applications.html#installing-r-packages"><i class="fa fa-check"></i><b>1.7.13</b> Installing R Packages</a></li>
<li class="chapter" data-level="1.7.14" data-path="software-applications.html"><a href="software-applications.html#loading-r-packages"><i class="fa fa-check"></i><b>1.7.14</b> Loading R Packages</a></li>
<li class="chapter" data-level="1.7.15" data-path="software-applications.html"><a href="software-applications.html#updating-r-packages"><i class="fa fa-check"></i><b>1.7.15</b> Updating R Packages</a></li>
<li class="chapter" data-level="1.7.16" data-path="software-applications.html"><a href="software-applications.html#useful-missing-data-packages-and-links"><i class="fa fa-check"></i><b>1.7.16</b> Useful Missing data Packages and links</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="missing-data-evaluation.html"><a href="missing-data-evaluation.html"><i class="fa fa-check"></i><b>2</b> Missing Data Evaluation</a><ul>
<li class="chapter" data-level="2.1" data-path="missing-data-evaluation.html"><a href="missing-data-evaluation.html#definition-of-missing-data"><i class="fa fa-check"></i><b>2.1</b> Definition of Missing Data</a><ul>
<li class="chapter" data-level="2.1.1" data-path="missing-data-evaluation.html"><a href="missing-data-evaluation.html#defining-missing-data-in-spss"><i class="fa fa-check"></i><b>2.1.1</b> Defining Missing Data in SPSS</a></li>
<li class="chapter" data-level="2.1.2" data-path="missing-data-evaluation.html"><a href="missing-data-evaluation.html#missing-data-in-r"><i class="fa fa-check"></i><b>2.1.2</b> Missing data in R</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="missing-data-evaluation.html"><a href="missing-data-evaluation.html#missing-data-patterns"><i class="fa fa-check"></i><b>2.2</b> Missing data Patterns</a><ul>
<li class="chapter" data-level="2.2.1" data-path="missing-data-evaluation.html"><a href="missing-data-evaluation.html#missing-data-patterns-in-spss"><i class="fa fa-check"></i><b>2.2.1</b> Missing data patterns in SPSS</a></li>
<li class="chapter" data-level="2.2.2" data-path="missing-data-evaluation.html"><a href="missing-data-evaluation.html#missing-data-patterns-in-r"><i class="fa fa-check"></i><b>2.2.2</b> Missing data patterns in R</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="missing-data-evaluation.html"><a href="missing-data-evaluation.html#missing-data-mechanisms"><i class="fa fa-check"></i><b>2.3</b> 2.3 Missing data Mechanisms</a><ul>
<li class="chapter" data-level="2.3.1" data-path="missing-data-evaluation.html"><a href="missing-data-evaluation.html#missing-completely-at-random"><i class="fa fa-check"></i><b>2.3.1</b> 2.3.1 Missing Completely At Random</a></li>
<li class="chapter" data-level="2.3.2" data-path="missing-data-evaluation.html"><a href="missing-data-evaluation.html#missing-at-random"><i class="fa fa-check"></i><b>2.3.2</b> Missing At Random</a></li>
<li class="chapter" data-level="2.3.3" data-path="missing-data-evaluation.html"><a href="missing-data-evaluation.html#missing-not-at-random"><i class="fa fa-check"></i><b>2.3.3</b> Missing Not At Random</a></li>
<li class="chapter" data-level="2.3.4" data-path="missing-data-evaluation.html"><a href="missing-data-evaluation.html#the-missing-data-indicator"><i class="fa fa-check"></i><b>2.3.4</b> The Missing Data Indicator</a></li>
<li class="chapter" data-level="2.3.5" data-path="missing-data-evaluation.html"><a href="missing-data-evaluation.html#the-role-of-auxiliary-variables"><i class="fa fa-check"></i><b>2.3.5</b> The Role of Auxiliary Variables</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="missing-data-evaluation.html"><a href="missing-data-evaluation.html#missing-data-evaluation-1"><i class="fa fa-check"></i><b>2.4</b> Missing Data evaluation</a><ul>
<li class="chapter" data-level="2.4.1" data-path="missing-data-evaluation.html"><a href="missing-data-evaluation.html#missing-data-evaluation-in-spss"><i class="fa fa-check"></i><b>2.4.1</b> Missing data Evaluation in SPSS</a></li>
<li class="chapter" data-level="2.4.2" data-path="missing-data-evaluation.html"><a href="missing-data-evaluation.html#missing-data-evaluation-in-r"><i class="fa fa-check"></i><b>2.4.2</b> Missing data Evaluation in R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="single-missing-data-imputations.html"><a href="single-missing-data-imputations.html"><i class="fa fa-check"></i><b>3</b> Single Missing data imputations</a><ul>
<li class="chapter" data-level="3.1" data-path="single-missing-data-imputations.html"><a href="single-missing-data-imputations.html#complete-cases-analysis"><i class="fa fa-check"></i><b>3.1</b> Complete cases analysis</a></li>
<li class="chapter" data-level="3.2" data-path="single-missing-data-imputations.html"><a href="single-missing-data-imputations.html#mean-imputation"><i class="fa fa-check"></i><b>3.2</b> Mean Imputation</a><ul>
<li class="chapter" data-level="3.2.1" data-path="single-missing-data-imputations.html"><a href="single-missing-data-imputations.html#mean-imputation-in-spss"><i class="fa fa-check"></i><b>3.2.1</b> Mean imputation in SPSS</a></li>
<li class="chapter" data-level="3.2.2" data-path="single-missing-data-imputations.html"><a href="single-missing-data-imputations.html#mean-imputation-in-r"><i class="fa fa-check"></i><b>3.2.2</b> Mean imputation in R</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="single-missing-data-imputations.html"><a href="single-missing-data-imputations.html#regression-imputation"><i class="fa fa-check"></i><b>3.3</b> Regression imputation</a><ul>
<li class="chapter" data-level="3.3.1" data-path="single-missing-data-imputations.html"><a href="single-missing-data-imputations.html#regression-imputation-in-spss"><i class="fa fa-check"></i><b>3.3.1</b> Regression imputation in SPSS</a></li>
<li class="chapter" data-level="3.3.2" data-path="single-missing-data-imputations.html"><a href="single-missing-data-imputations.html#regression-imputation-in-r"><i class="fa fa-check"></i><b>3.3.2</b> Regression imputation in R</a></li>
<li class="chapter" data-level="3.3.3" data-path="single-missing-data-imputations.html"><a href="single-missing-data-imputations.html#stochastic-regression-imputation"><i class="fa fa-check"></i><b>3.3.3</b> Stochastic regression imputation</a></li>
<li class="chapter" data-level="3.3.4" data-path="single-missing-data-imputations.html"><a href="single-missing-data-imputations.html#stochastic-regression-imputation-in-r"><i class="fa fa-check"></i><b>3.3.4</b> Stochastic regression imputation in R</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="single-missing-data-imputations.html"><a href="single-missing-data-imputations.html#bayesian-stochastic-regression-imputation"><i class="fa fa-check"></i><b>3.4</b> Bayesian Stochastic regression imputation</a><ul>
<li class="chapter" data-level="3.4.1" data-path="single-missing-data-imputations.html"><a href="single-missing-data-imputations.html#bayesian-stochastic-regression-imputation-in-spss"><i class="fa fa-check"></i><b>3.4.1</b> Bayesian Stochastic regression imputation in SPSS</a></li>
<li class="chapter" data-level="3.4.2" data-path="single-missing-data-imputations.html"><a href="single-missing-data-imputations.html#bayesian-stochastic-regression-imputation-in-r"><i class="fa fa-check"></i><b>3.4.2</b> Bayesian Stochastic regression imputation in R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="multiple-imputation.html"><a href="multiple-imputation.html"><i class="fa fa-check"></i><b>4</b> Multiple Imputation</a><ul>
<li class="chapter" data-level="4.1" data-path="multiple-imputation.html"><a href="multiple-imputation.html#multiple-imputation-1"><i class="fa fa-check"></i><b>4.1</b> Multiple Imputation</a></li>
<li class="chapter" data-level="4.2" data-path="multiple-imputation.html"><a href="multiple-imputation.html#multivariate-imputation-by-chained-equation-mice"><i class="fa fa-check"></i><b>4.2</b> Multivariate Imputation by Chained Equation (MICE)</a></li>
<li class="chapter" data-level="4.3" data-path="multiple-imputation.html"><a href="multiple-imputation.html#a-small-note-on-bayesian-imputation"><i class="fa fa-check"></i><b>4.3</b> 4.1. A small note on Bayesian Imputation</a></li>
<li class="chapter" data-level="4.4" data-path="multiple-imputation.html"><a href="multiple-imputation.html#running-multiple-imputation-in-r"><i class="fa fa-check"></i><b>4.4</b> 4.2. Running Multiple Imputation in R</a><ul>
<li class="chapter" data-level="4.4.1" data-path="multiple-imputation.html"><a href="multiple-imputation.html#the-mice-alogorithm-iand-iteration-steps"><i class="fa fa-check"></i><b>4.4.1</b> The mice alogorithm iand iteration steps</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="multiple-imputation.html"><a href="multiple-imputation.html#customizing-the-imputation-model"><i class="fa fa-check"></i><b>4.5</b> 4.3 Customizing the Imputation model</a></li>
<li class="chapter" data-level="4.6" data-path="multiple-imputation.html"><a href="multiple-imputation.html#output-of-the-mice-function"><i class="fa fa-check"></i><b>4.6</b> Output of the <code>mice</code> function</a></li>
<li class="chapter" data-level="4.7" data-path="multiple-imputation.html"><a href="multiple-imputation.html#checking-convergence-in-r"><i class="fa fa-check"></i><b>4.7</b> Checking Convergence in R</a></li>
<li class="chapter" data-level="4.8" data-path="multiple-imputation.html"><a href="multiple-imputation.html#imputation-diagnostics-in-r"><i class="fa fa-check"></i><b>4.8</b> Imputation diagnostics in R</a></li>
<li class="chapter" data-level="4.9" data-path="multiple-imputation.html"><a href="multiple-imputation.html#multiple-imputation-in-spss"><i class="fa fa-check"></i><b>4.9</b> Multiple imputation in SPSS</a><ul>
<li class="chapter" data-level="4.9.1" data-path="multiple-imputation.html"><a href="multiple-imputation.html#the-setting-for-multiple-imputation-in-spss"><i class="fa fa-check"></i><b>4.9.1</b> The setting for multiple imputation in SPSS</a></li>
<li class="chapter" data-level="4.9.2" data-path="multiple-imputation.html"><a href="multiple-imputation.html#the-output-for-multiple-imputation-in-spss"><i class="fa fa-check"></i><b>4.9.2</b> The output for Multiple imputation in SPSS</a></li>
<li class="chapter" data-level="4.9.3" data-path="multiple-imputation.html"><a href="multiple-imputation.html#checking-convergence-after-multiple-imputation-in-spss"><i class="fa fa-check"></i><b>4.9.3</b> Checking Convergence after Multiple imputation in SPSS</a></li>
</ul></li>
<li class="chapter" data-level="4.10" data-path="multiple-imputation.html"><a href="multiple-imputation.html#number-of-imputed-datasets-and-iterations"><i class="fa fa-check"></i><b>4.10</b> Number of Imputed datasets and iterations</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="data-analysis-after-multiple-imputation.html"><a href="data-analysis-after-multiple-imputation.html"><i class="fa fa-check"></i><b>5</b> Data analysis after Multiple Imputation</a><ul>
<li class="chapter" data-level="5.1" data-path="data-analysis-after-multiple-imputation.html"><a href="data-analysis-after-multiple-imputation.html#rubins-rules---a-first-example"><i class="fa fa-check"></i><b>5.1</b> Rubin’s Rules - A first example</a><ul>
<li class="chapter" data-level="5.1.1" data-path="data-analysis-after-multiple-imputation.html"><a href="data-analysis-after-multiple-imputation.html#pooling-parameters"><i class="fa fa-check"></i><b>5.1.1</b> Pooling Parameters</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="data-analysis-after-multiple-imputation.html"><a href="data-analysis-after-multiple-imputation.html#pooling-standard-errors"><i class="fa fa-check"></i><b>5.2</b> Pooling Standard errors</a></li>
<li class="chapter" data-level="5.3" data-path="data-analysis-after-multiple-imputation.html"><a href="data-analysis-after-multiple-imputation.html#significance-testing"><i class="fa fa-check"></i><b>5.3</b> Significance testing</a></li>
<li class="chapter" data-level="5.4" data-path="data-analysis-after-multiple-imputation.html"><a href="data-analysis-after-multiple-imputation.html#degrees-of-freedom-and-p-values"><i class="fa fa-check"></i><b>5.4</b> Degrees of Freedom and P-values</a></li>
<li class="chapter" data-level="5.5" data-path="data-analysis-after-multiple-imputation.html"><a href="data-analysis-after-multiple-imputation.html#measures-of-missing-data-information"><i class="fa fa-check"></i><b>5.5</b> Measures of Missing data information</a><ul>
<li class="chapter" data-level="5.5.1" data-path="data-analysis-after-multiple-imputation.html"><a href="data-analysis-after-multiple-imputation.html#fraction-of-missing-information"><i class="fa fa-check"></i><b>5.5.1</b> Fraction of Missing Information</a></li>
<li class="chapter" data-level="5.5.2" data-path="data-analysis-after-multiple-imputation.html"><a href="data-analysis-after-multiple-imputation.html#relative-increase-in-variance"><i class="fa fa-check"></i><b>5.5.2</b> Relative increase in variance</a></li>
<li class="chapter" data-level="5.5.3" data-path="data-analysis-after-multiple-imputation.html"><a href="data-analysis-after-multiple-imputation.html#fraction-of-missing-information---fmi"><i class="fa fa-check"></i><b>5.5.3</b> Fraction of Missing Information - FMI</a></li>
<li class="chapter" data-level="5.5.4" data-path="data-analysis-after-multiple-imputation.html"><a href="data-analysis-after-multiple-imputation.html#relative-efficiency"><i class="fa fa-check"></i><b>5.5.4</b> Relative Efficiency</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="data-analysis-after-multiple-imputation.html"><a href="data-analysis-after-multiple-imputation.html#pooling-data-analytic-results-after-mi-in-spss-and-r"><i class="fa fa-check"></i><b>5.6</b> Pooling Data Analytic results after MI in SPSS and R</a><ul>
<li class="chapter" data-level="5.6.1" data-path="data-analysis-after-multiple-imputation.html"><a href="data-analysis-after-multiple-imputation.html#pooling-means-and-standard-deviations-in-spss"><i class="fa fa-check"></i><b>5.6.1</b> Pooling Means and Standard deviations in SPSS</a></li>
<li class="chapter" data-level="5.6.2" data-path="data-analysis-after-multiple-imputation.html"><a href="data-analysis-after-multiple-imputation.html#pooling-means-and-standard-deviations-in-r"><i class="fa fa-check"></i><b>5.6.2</b> Pooling Means and Standard Deviations in R</a></li>
<li class="chapter" data-level="5.6.3" data-path="data-analysis-after-multiple-imputation.html"><a href="data-analysis-after-multiple-imputation.html#the-pooled-correlation-coefficient"><i class="fa fa-check"></i><b>5.6.3</b> 5.3.3 The Pooled Correlation coefficient</a></li>
<li class="chapter" data-level="5.6.4" data-path="data-analysis-after-multiple-imputation.html"><a href="data-analysis-after-multiple-imputation.html#the-pooled-independent-t-test"><i class="fa fa-check"></i><b>5.6.4</b> The Pooled Independent T-test</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="data-analysis-after-multiple-imputation.html"><a href="data-analysis-after-multiple-imputation.html#pooling-chi-square-tests"><i class="fa fa-check"></i><b>5.7</b> Pooling Chi-square tests</a></li>
<li class="chapter" data-level="5.8" data-path="data-analysis-after-multiple-imputation.html"><a href="data-analysis-after-multiple-imputation.html#analysis-of-variance-anova-pooling"><i class="fa fa-check"></i><b>5.8</b> Analysis of Variance (ANOVA) pooling</a></li>
<li class="chapter" data-level="5.9" data-path="data-analysis-after-multiple-imputation.html"><a href="data-analysis-after-multiple-imputation.html#pooling-regression-models"><i class="fa fa-check"></i><b>5.9</b> Pooling Regression models</a><ul>
<li class="chapter" data-level="5.9.1" data-path="data-analysis-after-multiple-imputation.html"><a href="data-analysis-after-multiple-imputation.html#the-pooled-linear-regression-model"><i class="fa fa-check"></i><b>5.9.1</b> The Pooled Linear Regression Model</a></li>
<li class="chapter" data-level="5.9.2" data-path="data-analysis-after-multiple-imputation.html"><a href="data-analysis-after-multiple-imputation.html#pooling-logistic-regression-models"><i class="fa fa-check"></i><b>5.9.2</b> Pooling Logistic Regression models</a></li>
<li class="chapter" data-level="5.9.3" data-path="data-analysis-after-multiple-imputation.html"><a href="data-analysis-after-multiple-imputation.html#pooling-cox-regression-models"><i class="fa fa-check"></i><b>5.9.3</b> Pooling Cox regression models</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="multiple-imputation-and-regression-modelling.html"><a href="multiple-imputation-and-regression-modelling.html"><i class="fa fa-check"></i><b>6</b> Multiple Imputation and Regression Modelling</a><ul>
<li class="chapter" data-level="6.1" data-path="multiple-imputation-and-regression-modelling.html"><a href="multiple-imputation-and-regression-modelling.html#imputing-the-outcome-variable"><i class="fa fa-check"></i><b>6.1</b> Imputing the Outcome variable</a></li>
<li class="chapter" data-level="6.2" data-path="multiple-imputation-and-regression-modelling.html"><a href="multiple-imputation-and-regression-modelling.html#logistic-regression-with-a-categorical-covariate-in-spss"><i class="fa fa-check"></i><b>6.2</b> Logistic regression with a categorical covariate in SPSS</a></li>
<li class="chapter" data-level="6.3" data-path="multiple-imputation-and-regression-modelling.html"><a href="multiple-imputation-and-regression-modelling.html#logistic-regression-with-a-categorical-variable-in-r"><i class="fa fa-check"></i><b>6.3</b> Logistic regression with a categorical variable in R</a><ul>
<li class="chapter" data-level="6.3.1" data-path="multiple-imputation-and-regression-modelling.html"><a href="multiple-imputation-and-regression-modelling.html#multiple-parameter-wald-test-or-d2-method"><i class="fa fa-check"></i><b>6.3.1</b> Multiple parameter Wald test or D2 method</a></li>
<li class="chapter" data-level="6.3.2" data-path="multiple-imputation-and-regression-modelling.html"><a href="multiple-imputation-and-regression-modelling.html#the-pooled-sampling-variance-or-d1-method"><i class="fa fa-check"></i><b>6.3.2</b> The pooled sampling variance or D1 method</a></li>
<li class="chapter" data-level="6.3.3" data-path="multiple-imputation-and-regression-modelling.html"><a href="multiple-imputation-and-regression-modelling.html#meng-and-rubin-pooling"><i class="fa fa-check"></i><b>6.3.3</b> Meng and Rubin pooling</a></li>
<li class="chapter" data-level="6.3.4" data-path="multiple-imputation-and-regression-modelling.html"><a href="multiple-imputation-and-regression-modelling.html#the-median-p-rule"><i class="fa fa-check"></i><b>6.3.4</b> The Median P Rule</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="multiple-imputation-and-regression-modelling.html"><a href="multiple-imputation-and-regression-modelling.html#cox-regression-with-a-categorical-variable-in-r"><i class="fa fa-check"></i><b>6.4</b> Cox Regression with a categorical variable in R</a><ul>
<li class="chapter" data-level="6.4.1" data-path="multiple-imputation-and-regression-modelling.html"><a href="multiple-imputation-and-regression-modelling.html#multiple-parameter-wald-test-or-d2-method-1"><i class="fa fa-check"></i><b>6.4.1</b> Multiple parameter Wald test or D2 method</a></li>
<li class="chapter" data-level="6.4.2" data-path="multiple-imputation-and-regression-modelling.html"><a href="multiple-imputation-and-regression-modelling.html#the-pooled-sampling-variance-or-d1-method-1"><i class="fa fa-check"></i><b>6.4.2</b> The pooled sampling variance or D1 method</a></li>
<li class="chapter" data-level="6.4.3" data-path="multiple-imputation-and-regression-modelling.html"><a href="multiple-imputation-and-regression-modelling.html#the-median-p-rule-1"><i class="fa fa-check"></i><b>6.4.3</b> The Median P Rule</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="multiple-imputation-and-regression-modelling.html"><a href="multiple-imputation-and-regression-modelling.html#predictor-selection"><i class="fa fa-check"></i><b>6.5</b> Predictor selection</a><ul>
<li class="chapter" data-level="6.5.1" data-path="multiple-imputation-and-regression-modelling.html"><a href="multiple-imputation-and-regression-modelling.html#predictor-selection-functions-in-r"><i class="fa fa-check"></i><b>6.5.1</b> Predictor Selection functions in R</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="multiple-imputation-and-regression-modelling.html"><a href="multiple-imputation-and-regression-modelling.html#interaction-terms-in-model"><i class="fa fa-check"></i><b>6.6</b> Interaction terms in model</a><ul>
<li class="chapter" data-level="6.6.1" data-path="multiple-imputation-and-regression-modelling.html"><a href="multiple-imputation-and-regression-modelling.html#imputation-of-interaction-terms-in-spss"><i class="fa fa-check"></i><b>6.6.1</b> Imputation of interaction terms in SPSS</a></li>
<li class="chapter" data-level="6.6.2" data-path="multiple-imputation-and-regression-modelling.html"><a href="multiple-imputation-and-regression-modelling.html#imputation-of-interaction-terms-in-r"><i class="fa fa-check"></i><b>6.6.2</b> Imputation of interaction terms in R</a></li>
<li class="chapter" data-level="6.6.3" data-path="multiple-imputation-and-regression-modelling.html"><a href="multiple-imputation-and-regression-modelling.html#comparing-methods"><i class="fa fa-check"></i><b>6.6.3</b> Comparing methods</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="advanced-multiple-imputation-models-for-multilevel-data.html"><a href="advanced-multiple-imputation-models-for-multilevel-data.html"><i class="fa fa-check"></i><b>7</b> Advanced Multiple Imputation models for Multilevel data</a><ul>
<li class="chapter" data-level="7.1" data-path="advanced-multiple-imputation-models-for-multilevel-data.html"><a href="advanced-multiple-imputation-models-for-multilevel-data.html#characteristics-of-multilevel-data"><i class="fa fa-check"></i><b>7.1</b> Characteristics of Multilevel data</a></li>
<li class="chapter" data-level="7.2" data-path="advanced-multiple-imputation-models-for-multilevel-data.html"><a href="advanced-multiple-imputation-models-for-multilevel-data.html#multilevel-data---from-wide-to-long"><i class="fa fa-check"></i><b>7.2</b> Multilevel data - from wide to long</a></li>
<li class="chapter" data-level="7.3" data-path="advanced-multiple-imputation-models-for-multilevel-data.html"><a href="advanced-multiple-imputation-models-for-multilevel-data.html#multilevel-data---from-wide-to-long-1"><i class="fa fa-check"></i><b>7.3</b> Multilevel data - from wide to long</a></li>
<li class="chapter" data-level="7.4" data-path="advanced-multiple-imputation-models-for-multilevel-data.html"><a href="advanced-multiple-imputation-models-for-multilevel-data.html#multilevel-data---clusters-and-levels"><i class="fa fa-check"></i><b>7.4</b> Multilevel data - Clusters and Levels</a></li>
<li class="chapter" data-level="7.5" data-path="advanced-multiple-imputation-models-for-multilevel-data.html"><a href="advanced-multiple-imputation-models-for-multilevel-data.html#the-multilevel-model"><i class="fa fa-check"></i><b>7.5</b> The Multilevel model</a></li>
<li class="chapter" data-level="7.6" data-path="advanced-multiple-imputation-models-for-multilevel-data.html"><a href="advanced-multiple-imputation-models-for-multilevel-data.html#restructuring-datasets-from-wide-to-long-in-spss"><i class="fa fa-check"></i><b>7.6</b> Restructuring datasets from wide to long in SPSS</a><ul>
<li class="chapter" data-level="7.6.1" data-path="advanced-multiple-imputation-models-for-multilevel-data.html"><a href="advanced-multiple-imputation-models-for-multilevel-data.html#restructuring-a-dataset-from-wide-to-long-in-r"><i class="fa fa-check"></i><b>7.6.1</b> Restructuring a dataset from wide to long in R</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="advanced-multiple-imputation-models-for-multilevel-data.html"><a href="advanced-multiple-imputation-models-for-multilevel-data.html#missing-data-at-different-levels"><i class="fa fa-check"></i><b>7.7</b> Missing data at different levels</a></li>
<li class="chapter" data-level="7.8" data-path="advanced-multiple-imputation-models-for-multilevel-data.html"><a href="advanced-multiple-imputation-models-for-multilevel-data.html#multilevel-imputation-models"><i class="fa fa-check"></i><b>7.8</b> Multilevel imputation models</a><ul>
<li class="chapter" data-level="7.8.1" data-path="advanced-multiple-imputation-models-for-multilevel-data.html"><a href="advanced-multiple-imputation-models-for-multilevel-data.html#sporadically-and-systematically-missing-data"><i class="fa fa-check"></i><b>7.8.1</b> Sporadically and Systematically missing data</a></li>
</ul></li>
<li class="chapter" data-level="7.9" data-path="advanced-multiple-imputation-models-for-multilevel-data.html"><a href="advanced-multiple-imputation-models-for-multilevel-data.html#one-stage-multilevel-imputation"><i class="fa fa-check"></i><b>7.9</b> One stage Multilevel Imputation</a><ul>
<li class="chapter" data-level="7.9.1" data-path="advanced-multiple-imputation-models-for-multilevel-data.html"><a href="advanced-multiple-imputation-models-for-multilevel-data.html#one-stage-multilevel-imputation-in-r"><i class="fa fa-check"></i><b>7.9.1</b> One stage Multilevel Imputation in R</a></li>
</ul></li>
<li class="chapter" data-level="7.10" data-path="advanced-multiple-imputation-models-for-multilevel-data.html"><a href="advanced-multiple-imputation-models-for-multilevel-data.html#missing-data-at-different-levels-1"><i class="fa fa-check"></i><b>7.10</b> Missing data at different levels</a></li>
<li class="chapter" data-level="7.11" data-path="advanced-multiple-imputation-models-for-multilevel-data.html"><a href="advanced-multiple-imputation-models-for-multilevel-data.html#multilevel-imputation-models-1"><i class="fa fa-check"></i><b>7.11</b> Multilevel imputation models</a><ul>
<li class="chapter" data-level="7.11.1" data-path="advanced-multiple-imputation-models-for-multilevel-data.html"><a href="advanced-multiple-imputation-models-for-multilevel-data.html#sporadically-and-systematically-missing-data-1"><i class="fa fa-check"></i><b>7.11.1</b> Sporadically and Systematically missing data</a></li>
<li class="chapter" data-level="7.11.2" data-path="advanced-multiple-imputation-models-for-multilevel-data.html"><a href="advanced-multiple-imputation-models-for-multilevel-data.html#one-stage-multilevel-imputation-1"><i class="fa fa-check"></i><b>7.11.2</b> One stage Multilevel Imputation</a></li>
<li class="chapter" data-level="7.11.3" data-path="advanced-multiple-imputation-models-for-multilevel-data.html"><a href="advanced-multiple-imputation-models-for-multilevel-data.html#one-stage-multilevel-imputation-in-r-1"><i class="fa fa-check"></i><b>7.11.3</b> One stage Multilevel Imputation in R</a></li>
</ul></li>
<li class="chapter" data-level="7.12" data-path="advanced-multiple-imputation-models-for-multilevel-data.html"><a href="advanced-multiple-imputation-models-for-multilevel-data.html#two-stage-multilevel-imputation"><i class="fa fa-check"></i><b>7.12</b> Two stage Multilevel Imputation</a><ul>
<li class="chapter" data-level="7.12.1" data-path="advanced-multiple-imputation-models-for-multilevel-data.html"><a href="advanced-multiple-imputation-models-for-multilevel-data.html#two-stage-multilevel-imputation-in-r"><i class="fa fa-check"></i><b>7.12.1</b> Two stage Multilevel Imputation in R</a></li>
</ul></li>
<li class="chapter" data-level="7.13" data-path="advanced-multiple-imputation-models-for-multilevel-data.html"><a href="advanced-multiple-imputation-models-for-multilevel-data.html#the-micemd-package"><i class="fa fa-check"></i><b>7.13</b> The micemd Package</a></li>
<li class="chapter" data-level="7.14" data-path="advanced-multiple-imputation-models-for-multilevel-data.html"><a href="advanced-multiple-imputation-models-for-multilevel-data.html#pooling-multilevel-models"><i class="fa fa-check"></i><b>7.14</b> Pooling Multilevel models</a><ul>
<li class="chapter" data-level="7.14.1" data-path="advanced-multiple-imputation-models-for-multilevel-data.html"><a href="advanced-multiple-imputation-models-for-multilevel-data.html#pooling-multilevel-models-in-r"><i class="fa fa-check"></i><b>7.14.1</b> Pooling Multilevel Models in R</a></li>
<li class="chapter" data-level="7.14.2" data-path="advanced-multiple-imputation-models-for-multilevel-data.html"><a href="advanced-multiple-imputation-models-for-multilevel-data.html#pooling-multilevel-models-in-spss"><i class="fa fa-check"></i><b>7.14.2</b> Pooling Multilevel Models in SPSS</a></li>
</ul></li>
<li class="chapter" data-level="7.15" data-path="advanced-multiple-imputation-models-for-multilevel-data.html"><a href="advanced-multiple-imputation-models-for-multilevel-data.html#pooling-gee-models"><i class="fa fa-check"></i><b>7.15</b> Pooling GEE models</a><ul>
<li class="chapter" data-level="7.15.1" data-path="advanced-multiple-imputation-models-for-multilevel-data.html"><a href="advanced-multiple-imputation-models-for-multilevel-data.html#pooling-gee-models-in-r"><i class="fa fa-check"></i><b>7.15.1</b> Pooling GEE Models in R</a></li>
<li class="chapter" data-level="7.15.2" data-path="advanced-multiple-imputation-models-for-multilevel-data.html"><a href="advanced-multiple-imputation-models-for-multilevel-data.html#pooling-gee-models-in-spss"><i class="fa fa-check"></i><b>7.15.2</b> Pooling GEE Models in SPSS</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Applied Missing data analysis with SPSS and R(Studio)</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="multiple-imputation" class="section level1">
<h1><span class="header-section-number">Chapter 4</span> Multiple Imputation</h1>
<div id="multiple-imputation-1" class="section level2">
<h2><span class="header-section-number">4.1</span> Multiple Imputation</h2>
<p>In this Chapter we discuss an advanced missing data handling method, that is called Multiple Imputation (MI). With MI, each missing value is replaced by several different values and consequently several different completed datasets are generated. The complete data is copied repeatedly in the completed datasets. The concept of MI can be made clear by the following figure 4.1.</p>
<div class="figure" style="text-align: center">
<img src="images/fig4.1.png" alt="Graphical presentation of the MI procedure. " width="90%" />
<p class="caption">
(#fig:fig4.1)Graphical presentation of the MI procedure.
</p>
</div>
<p>The large square on the left represents a dataset with missing values, with the missing values indicated as small solid black squares. The squares in the middle that are numbered from 1 to 5 are the separate imputed and completed datasets and the square on the right represents the combined study results.</p>
<p>Figure 4.1 shows that the imputation of missing values consists of three steps, first the missing values are imputed, subsequently statistical analyses are applied in each completed dataset and finally the statistical test results from these analyses are synthesized by combining the sperate analysis results into one pooled estimate.</p>
</div>
<div id="multivariate-imputation-by-chained-equation-mice" class="section level2">
<h2><span class="header-section-number">4.2</span> Multivariate Imputation by Chained Equation (MICE)</h2>
<p>The main MI method that is discussed in this manual is Multivariate imputation by chained equations (MICE), also known as Sequential Regression Imputation, Fully Conditional Specification or Gibbs sampling (ref). In the MICE algorithm, a chain of regression equations is used to obtain imputations, which means that variables with missing data are imputed one by one using a chain of regression models. These regression models make use of information of all other variables in the model, i.e. conditional imputation models. Essentially, applying MI is the same as repeating stochastic regression imputation over several imputation runs or chains to impute the missing data sequentially in different variables.</p>
<p>Another multiple imputation procedure is called multivariate normal</p>
<p>In this Chapter, the first phase in multiple imputation, that of the imputation step is the main topic. In the next Chapter, the analysis and pooling phase will be discussed. First, we start with a small note about Bayesian statistics because the default imputation procedure in MI uses Bayesian statistics to generate the missing values and this is important to understand. We will discuss Bayesian statistics conceptually. For a better understanding of Bayesian statistics, we refer to the books of Knight, Enders (2010), Gelman (2004), Box and Tiao (1973) and Rubin (1987). The book of Enders is the least technical and a good book to start with as an introduction into Bayesian statistics for missing data and to get a better understanding of Bayesian estimation. The other books are theoretical and you must have a firm understanding of statistics and no fear of formulas to read those.</p>
</div>
<div id="a-small-note-on-bayesian-imputation" class="section level2">
<h2><span class="header-section-number">4.3</span> 4.1. A small note on Bayesian Imputation</h2>
<p>Within the MI algorithm we account for imputation uncertainty by replacing the missing values multiple times. Values are predicted by using regression parameters. With regression parameters we mean the parameters that result from applying a regression model to a dataset. The estimates from a (regression) model, like regression coefficients or the error variance, are called parameters in statistics. What separates the non-Bayesian from the Bayesian imputation procedures is how the regression parameters are estimated. In the context of linear regression modeling these parameters are the regression coefficients and the residual error variance. Non-Bayesian regression imputation models account for the uncertainty in the missing values, by adding error variance to imputed values that are estimated from the regression line as in stochastic regression imputation (paragraph 3.5). This is done in each imputed dataset. Bayesian regression imputation models also add variation to the regression coefficients as in Bayesian stochastic regression imputation (paragraph 3.6). Thus, the difference between non-Bayesian and Bayesian imputation is that in the latter procedure not only extra variation is added via the residual error variance, but also via the (population) regression coefficients (in essence also for the error variance component a Bayesian estimate is used).</p>
<p>We have seen an example of Bayesian and non-Bayesian imputation in Chapter 3 when we compared the Bayesian and non-Bayesian stochastic regression imputation procedure. By adding extra variation to the regression coefficients, as with Bayesian Stochastic regression imputation models, we take into account that the regression coefficient by itself is surrounded by uncertainty. In other words, we use the idea that there is not one true (population) regression coefficient but that the regression coefficient, as the (true) population parameter, follows a (probability) distribution itself. This is in contrast to a frequentist idea, which assumes that there is one true population parameter and that the uncertainty (by using a confidence interval) around the population parameter can be interpreted as a probability statement of the result if the study would be repeated infinite times. In the frequentist approach the sample regression coefficient is estimated by assuming that the regression coefficient, when repeating the study infinite times, follow a normal distribution. We use the sample regression coefficient as the best estimator of the population regression coefficient and present these with the confidence interval for the true population estimate. In contrast, in a Bayesian context, a Bayesian interval is a direct reflection of the uncertainty of the population regression coefficient. This means that, for Bayesian estimates, we directly compute the probability distribution of the regression coefficient itself. In other words, Bayesian statistics assume that the regression coefficient is a random variable that has a distribution.</p>
<pre><code>What makes Bayesian estimation complex is that the distribution of the regression coefficient itself has to be estimated. This means that an estimation method has to be used to derive this distribution. Markov Chain Monte Carlo (MCMC) methods can help with this. A popular MCMC method to construct this distribution is the Gibbs Sampler. The Gibbs sampler produces a chain of iterations and updates regression parameters at each iteration step. This procedure is also used by the Multivariate Imputation by Chained Equations (MICE) package, that is the main MI method discussed in this manual, and therefore the MICE procedure is also called Gibbs sampling.

Bayesian estimates are used to incorporate parameter uncertainty, e.g. uncertainty in the regression coefficient, that is used to generate the imputed values (on top of the error variance). Consequently, imputed values are drawn from their posterior predictive distribution, conditional on the values of other variables. Posterior, in Bayesian statistics, refers to an estimate, e.g. a regression coefficient estimate, that is estimated by using the sample data together with prior information about the value of the regression coefficient. This combination of sample data and prior information leads to a posterior estimated value of the regression coefficient, i.e. the posterior distribution. The Gibbs sampler helps to estimate this posterior value, that is subsequently used in a regression model to generate imputed values. Conditional, means loosely that we make use of the idea that variables are related to each other. For example, the value of the Tampa scale variable, relates to  for example the Pain, Gender and Disability variables. The more we know about the values of Pain, Gender or Disability, the better we can estimate the value for the Tampa scale. This relation is important because this relation can be used to generate imputations for the Tampa scale variable. If Tampa scale values are missing for specific values of Pain, Gender and Disability, these variables can be used to impute the Tampa scale scores. These relationships are captured by specifying a regression model with the Tampa scale as the outcome variable and Pain, Gender and Disability as the independent variables. We use these regression models to estimate imputed values for the Tampa scale score conditional on the Pain, Gender and Disability scores. A posterior predictive distribution means that we first use the posterior distribution, i.e. determined by using the Gibbs sampler, to draw a regression coefficient from and that we use that regression coefficient and the observed data to predict the missing value by using a regression equation. </code></pre>
</div>
<div id="running-multiple-imputation-in-r" class="section level2">
<h2><span class="header-section-number">4.4</span> 4.2. Running Multiple Imputation in R</h2>
<p>Multipl imputation in R can be performed with the <code>mice</code> function from the <code>mice</code> package. As an example we will apply this function to deal with the missing values in the LBP dataset of 50 low back pain patients. The dataset contains missing data in the two continuous variables, the Tampa scale and the Disability variable. The other variables in the dataset are Pain and Radiation, which are completely observed.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data &lt;-<span class="st"> </span><span class="kw">read_sav</span>(<span class="st">&quot;data/Backpain50 MI missing.sav&quot;</span>)
<span class="kw">head</span>(data,<span class="dv">15</span>)</code></pre></div>
<pre><code>## # A tibble: 15 x 5
##       ID  Pain Tampascale Disability Radiation
##    &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;
##  1     1     9         45         20         1
##  2     2     6         NA         10         0
##  3     3     1         36          1         0
##  4     4     5         38         NA         0
##  5     5     6         44         14         1
##  6     6     7         NA         11         1
##  7     7     8         43         NA         0
##  8     8     6         43         11         1
##  9     9     2         NA         11         1
## 10    10     4         36         NA         0
## 11    11     5         38         16         1
## 12    12     9         47         14         0
## 13    13     0         32          3         1
## 14    14     6         NA         12         0
## 15    15     3         34         13         0</code></pre>
<p>The variable with missing values is always defined as the dependent variable and all other variables in the imputation model are the independent variables. During each iteration, all variables with missing values are imputed.</p>
<p>The following options are used in the <code>mice</code> function to start MI, <code>m=5</code>, to generate 5 imputed datasets, <code>maxit=10</code>, to use 10 iterations for each imputed dataset (i.e. 10 chains of regression imputation models), <code>method=”pmm”</code>, which is the default imputation procedure in mice (see <code>?mice</code> for all settings of the mice function). We can also add a seed value to be able to obtain the same results when we repeat the analysis.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(mice)
imp &lt;-<span class="st"> </span><span class="kw">mice</span>(data, <span class="dt">m=</span><span class="dv">5</span>, <span class="dt">maxit=</span><span class="dv">10</span>, <span class="dt">method=</span><span class="st">&quot;pmm&quot;</span>, <span class="dt">seed=</span><span class="dv">1050</span>)</code></pre></div>
<pre><code>## 
##  iter imp variable
##   1   1  Tampascale  Disability
##   1   2  Tampascale  Disability
##   1   3  Tampascale  Disability
##   1   4  Tampascale  Disability
##   1   5  Tampascale  Disability
##   2   1  Tampascale  Disability
##   2   2  Tampascale  Disability
##   2   3  Tampascale  Disability
##   2   4  Tampascale  Disability
##   2   5  Tampascale  Disability
##   3   1  Tampascale  Disability
##   3   2  Tampascale  Disability
##   3   3  Tampascale  Disability
##   3   4  Tampascale  Disability
##   3   5  Tampascale  Disability
##   4   1  Tampascale  Disability
##   4   2  Tampascale  Disability
##   4   3  Tampascale  Disability
##   4   4  Tampascale  Disability
##   4   5  Tampascale  Disability
##   5   1  Tampascale  Disability
##   5   2  Tampascale  Disability
##   5   3  Tampascale  Disability
##   5   4  Tampascale  Disability
##   5   5  Tampascale  Disability
##   6   1  Tampascale  Disability
##   6   2  Tampascale  Disability
##   6   3  Tampascale  Disability
##   6   4  Tampascale  Disability
##   6   5  Tampascale  Disability
##   7   1  Tampascale  Disability
##   7   2  Tampascale  Disability
##   7   3  Tampascale  Disability
##   7   4  Tampascale  Disability
##   7   5  Tampascale  Disability
##   8   1  Tampascale  Disability
##   8   2  Tampascale  Disability
##   8   3  Tampascale  Disability
##   8   4  Tampascale  Disability
##   8   5  Tampascale  Disability
##   9   1  Tampascale  Disability
##   9   2  Tampascale  Disability
##   9   3  Tampascale  Disability
##   9   4  Tampascale  Disability
##   9   5  Tampascale  Disability
##   10   1  Tampascale  Disability
##   10   2  Tampascale  Disability
##   10   3  Tampascale  Disability
##   10   4  Tampascale  Disability
##   10   5  Tampascale  Disability</code></pre>
<p>After we have run the mice function, information is provided about the iteration and imputation steps for the variable that are imputed under the columns named “iter”, “imp” and “variable”. This information can be turned off by setting the mice function parameter printFlag = FALSE, which results in silent computation of the missing values. However, the printed information gives feedback about at which iteration step the imputation algorithm is, which gives you an idea how long it takes until the imputations are finished. The results from the imputation can be viewed by calling the imp object.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">imp</code></pre></div>
<pre><code>## Class: mids
## Number of multiple imputations:  5 
## Imputation methods:
##         ID       Pain Tampascale Disability  Radiation 
##         &quot;&quot;         &quot;&quot;      &quot;pmm&quot;      &quot;pmm&quot;         &quot;&quot; 
## PredictorMatrix:
##            ID Pain Tampascale Disability Radiation
## ID          0    1          1          1         1
## Pain        1    0          1          1         1
## Tampascale  1    1          0          1         1
## Disability  1    1          1          0         1
## Radiation   1    1          1          1         0</code></pre>
<p>Under this object is information of the function that is called call (function settings that we used for mice), the number of imputed datasets, the missing values in each variable, the imputation method, the information under VisitSequence which is information about the sequence of variables that are firstly, secondly, etc. imputed during the imputation process, information of the PredictorMatrix (see paragraph XX) and the seed value of the random number generator.</p>
<p>The MI datasets can be extracted by using the complete function (R code 4.4). The settings action=”long” and include=T mean that the imputed datasets are stacked under each other and that the original dataset (with missings) is also included (see ?complete for more possibilities how to store the imputed datasets).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mi_long &lt;-<span class="st"> </span><span class="kw">complete</span>(imp, <span class="dt">action=</span><span class="st">&quot;long&quot;</span>, <span class="dt">include=</span>T)</code></pre></div>
<p>In the imputed datasets two variables are added, an .id variable and an .imp variable to distinguish the cases in the dataset and the imputed datasets. The imputed datasets can be further used in mice to conduct pooled analyses or to store them for further use in other software packages as SPSS.</p>
<div id="the-mice-alogorithm-iand-iteration-steps" class="section level3">
<h3><span class="header-section-number">4.4.1</span> The mice alogorithm iand iteration steps</h3>
<p>Imputed dataset 1 Per imputed dataset we start with iteration number 0 (not shown in output).</p>
<p>Iteration 0: Data points are randomly drawn from the observed values of the Tampascale and the Disability variable and these are used to replace the missing values in these variables.</p>
<p>Iteration 1 (cycle 1): The Tampascale values are set back to missing. Then, a linear regression model is applied in the available data (i.e. complete case analysis) with the Tampascale as the dependent and Pain, Disability and Radiation as independent variables to their regression coefficient estimates that are used to predict the missing values in the Tampascale variable together with the completed variables, i.e. the completed Disability variable from iteration 0 (indicated by Disability0, because only the Disability variable contained missing data at this stage) and the available data from the Pain and Radiation variable (which were complete). This regression equation is defined as:</p>
<p>Tampascale_mis= B_0+ B_1× Pain+ B_2× Disability_0+ B_3× Radiation</p>
<p>The same procedure is repeated for the Disability variable. The Disability scores are first set back to missing, then the regression coefficients of the Pain, Tampa scale and Radiation variables are obtained in the complete case dataset and imputations are generated from these regression coefficients. The missing values for Disability are imputed by using the imputed values in the Tampa scale variable (indicated by Tampa scale1, i.e. which were imputed from the previous regression model).</p>
<p>Disability _mis= B_0+ B_1× Pain+ B_2× Tampascale _1+ B_3× Radiation</p>
<p>Iteration 2 (cycle 2):</p>
<p>The Tampascale values are again set back to missing and (new) updated regression coefficients for Pain, Disability and Radiation are obtained, making use of the imputed values in the Disability variable from iteration 1 (indicated by Disability1) and the complete data of the Pain and Radiation variables. Subsequently, missing values are updated from that regression model.</p>
<p>Tampascale _mis= B_0+ B_1× Pain+ B_2× Disability _1+ B_3× Radiation</p>
<p>The same holds for the Disability variable. The missing values are updated by making use of the imputed values in the Tampascale variable within iteration 2 (indicated by Tampascale2) and updated regression coefficients.</p>
<p>Disability _mis= B_0+ B_1× Pain+ B_2× Tampascale _2+ B_3× Radiation</p>
<p>Iteration 3 to prespecified number of iterations: This process is repeated within each iteration</p>
<p>Last iteration: The imputed values from the last iteration are used in the imputed dataset. For the next imputed dataset, the entire process of iterations is repeated.</p>
</div>
</div>
<div id="customizing-the-imputation-model" class="section level2">
<h2><span class="header-section-number">4.5</span> 4.3 Customizing the Imputation model</h2>
<pre><code>With MI the variables Tampa scale and Disability will be imputed with the help of the variables Pain and Radiation. The latter two variables are called auxiliary variables when they are not part of the main analysis model but they help to impute the Tampa scale and Function variables. Variables that are used to impute other variables can be switched off and on in the predictormatrix. As we saw in R code 4.3 above, the predictor matrix for our MI procedure is</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">imp<span class="op">$</span>PredictorMatrix</code></pre></div>
<pre><code>## NULL</code></pre>
<p>The predictor matrix is a matrix with the names of the variables that are part of the imputation model in the dataset listed in the rows and the column. The variables in the columns can be switched on or off which is the same as in- or excluding them from the imputation model to impute the missing data in the row variable. This works as follows for our LBP dataset. The first and fourth rows contain only zero´s, which is logical, because the Pain and Radiation variables did not have missing values. The variable in the second row contains missing values and the 1´s in this row mean that the column variables, Pain, Disability and Radiation will be included in the (regression) imputation model. To impute the missing data in the Disability variable, the column variables Pain, Tampa scale and Radiation are used. As a default setting all variables will be included in the imputation model to predict missing values in other variables, i.e. as default all combinations of variables that are complete and have missing values in the matrix will be switched on, i.e. are assigned a value 1 in the predictormatrix. The diagonal of the predictormatrix is always zero. The predictormatrix can also be adapted when for example a variable that contains a high percentage of missing data must be excluded from the imputation model to impute other variables. For example, if we want to exclude the variable Disability from the imputation model of the Tampa scale variable and re-run the MI, we can use the following code:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pred &lt;-imp<span class="op">$</span>PredictorMatrix
pred[<span class="st">&quot;Tampascale&quot;</span>, <span class="st">&quot;Disability&quot;</span>] &lt;-<span class="st"> </span><span class="dv">0</span>
pred

imp2 &lt;-<span class="st"> </span><span class="kw">mice</span>(data,<span class="dt">m=</span><span class="dv">5</span>, <span class="dt">maxit=</span><span class="dv">10</span>, <span class="dt">method=</span><span class="st">&quot;pmm&quot;</span>, <span class="dt">predictorMatrix =</span> pred, <span class="dt">seed=</span><span class="dv">1050</span>)</code></pre></div>
<p>For information about the imputation model can be foud in REF van buuren, REF White etc. A summary of guidelines for building the imptuation model is as follows:</p>
<ol style="list-style-type: decimal">
<li><p>Include the outcome variable (Moons, 2006).</p></li>
<li><p>Include all variables that are part of the analysis model.</p></li>
<li><p>Include the variables at the same way in the imputation model as they appear in the analysis model (i.e. if interaction terms are in the analysis model they also have to be included in the imputation model).</p></li>
<li><p>Include as many predictor variables that are related to missingness in other variables or that are correlated to the variable with missing values (auxiliary variables).</p></li>
</ol>
</div>
<div id="output-of-the-mice-function" class="section level2">
<h2><span class="header-section-number">4.6</span> Output of the <code>mice</code> function</h2>
<p>The mice function returns a mids (multiple imputed data set) object. In our example that is the imp object. Under this object, all kind of imputation information is stored and can be extracted by typing <code>imp$</code>, followed by the type of information you want.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">imp<span class="op">$</span>m</code></pre></div>
<pre><code>## [1] 5</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">imp<span class="op">$</span>nmis</code></pre></div>
<pre><code>##         ID       Pain Tampascale Disability  Radiation 
##          0          0         13          9          0</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">imp<span class="op">$</span>seed</code></pre></div>
<pre><code>## [1] 1050</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">imp<span class="op">$</span>iteration</code></pre></div>
<pre><code>## [1] 10</code></pre>
<p>The above objects contain the the number of imputed datasets, missing values in each variable, the specified seed value and the number of iterations. The original data can be found in:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">imp<span class="op">$</span>data</code></pre></div>
<pre><code>##    ID Pain Tampascale Disability Radiation
## 1   1    9         45         20         1
## 2   2    6         NA         10         0
## 3   3    1         36          1         0
## 4   4    5         38         NA         0
## 5   5    6         44         14         1
## 6   6    7         NA         11         1
## 7   7    8         43         NA         0
## 8   8    6         43         11         1
## 9   9    2         NA         11         1
## 10 10    4         36         NA         0
## 11 11    5         38         16         1
## 12 12    9         47         14         0
## 13 13    0         32          3         1
## 14 14    6         NA         12         0
## 15 15    3         34         13         0
## 16 16    6         42         NA         1
## 17 17    3         35         11         0
## 18 18    1         31          1         0
## 19 19    2         31          7         0
## 20 20    4         32          9         1
## 21 21    5         NA         13         0
## 22 22    5         39         12         0
## 23 23    4         34          8         1
## 24 24    8         47         13         1
## 25 25    5         NA          6         0
## 26 26    5         38         16         1
## 27 27    9         NA         23         1
## 28 28    3         36         NA         1
## 29 29    2         36          9         0
## 30 30    6         37         16         0
## 31 31   10         NA         21         1
## 32 32    4         37          8         0
## 33 33   10         42         20         1
## 34 34    2         37          3         0
## 35 35    6         NA         12         1
## 36 36    3         38          7         1
## 37 37    8         NA          8         0
## 38 38    3         38          6         1
## 39 39    3         39         NA         0
## 40 40    7         44         15         0
## 41 41    7         45         NA         0
## 42 42    6         40         12         1
## 43 43    7         40         16         1
## 44 44    1         NA          2         0
## 45 45    9         41         NA         0
## 46 46    5         41         17         0
## 47 47    6         43         11         0
## 48 48    3         39         NA         0
## 49 49    2         NA          6         1
## 50 50    8         NA         19         0</code></pre>
<p>The imputed values for each variable in the imptued values can be found under:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">imp<span class="op">$</span>imp</code></pre></div>
<pre><code>## $ID
## [1] 1 2 3 4 5
## &lt;0 rows&gt; (or 0-length row.names)
## 
## $Pain
## [1] 1 2 3 4 5
## &lt;0 rows&gt; (or 0-length row.names)
## 
## $Tampascale
##     1  2  3  4  5
## 2  44 43 37 37 40
## 6  44 45 37 43 43
## 9  36 36 36 36 31
## 14 44 37 43 43 40
## 21 44 41 37 39 41
## 25 47 42 44 40 44
## 27 44 43 44 45 44
## 31 45 43 43 47 43
## 35 44 37 42 40 40
## 37 42 47 47 47 47
## 44 38 31 37 35 31
## 49 34 38 34 36 37
## 50 45 44 43 47 45
## 
## $Disability
##     1  2  3  4  5
## 4  12 13 12 14 13
## 7  13 19 16 14 13
## 10 13  8  6  6  6
## 16 11 12  9 11 16
## 28  6 12  6 11 11
## 39 11 11  7 11  9
## 41 12 11 10 12 10
## 45 20 20 14 23 14
## 48  9 11  6  7  7
## 
## $Radiation
## [1] 1 2 3 4 5
## &lt;0 rows&gt; (or 0-length row.names)</code></pre>
<p>The imputation methods used:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">imp<span class="op">$</span>method</code></pre></div>
<pre><code>##         ID       Pain Tampascale Disability  Radiation 
##         &quot;&quot;         &quot;&quot;      &quot;pmm&quot;      &quot;pmm&quot;         &quot;&quot;</code></pre>
<p>The predictor matrix:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">imp<span class="op">$</span>predictorMatrix</code></pre></div>
<pre><code>##            ID Pain Tampascale Disability Radiation
## ID          0    1          1          1         1
## Pain        1    0          1          1         1
## Tampascale  1    1          0          1         1
## Disability  1    1          1          0         1
## Radiation   1    1          1          1         0</code></pre>
<p>The sequence of the variables used in the imputeon procedure:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">imp<span class="op">$</span>visitSequence</code></pre></div>
<pre><code>## [1] &quot;ID&quot;         &quot;Pain&quot;       &quot;Tampascale&quot; &quot;Disability&quot; &quot;Radiation&quot;</code></pre>
<p>The imputed values (or means) during each iteration can also be extracted. These are stored as chainMean. The number of Chains is equal to the number of imputed datasets. A Chain refers to the chain of regression models that is used to generate the missing values. The length of each chain is equally large as the number of iterations. The Chains contain the means of the imputed values. This object can be used for monitoring convergence (by for example displaying the results in a convergence plot. See the next paragraph).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">imp<span class="op">$</span>chainMean</code></pre></div>
<pre><code>## , , Chain 1
## 
##                   1        2        3        4        5        6        7
## ID              NaN      NaN      NaN      NaN      NaN      NaN      NaN
## Pain            NaN      NaN      NaN      NaN      NaN      NaN      NaN
## Tampascale 39.30769 41.38462 40.92308 39.84615 39.38462 38.92308 41.23077
## Disability 12.00000 12.33333 13.88889 11.55556 11.55556 12.44444 11.55556
## Radiation       NaN      NaN      NaN      NaN      NaN      NaN      NaN
##                    8        9       10
## ID               NaN      NaN      NaN
## Pain             NaN      NaN      NaN
## Tampascale 38.846154 39.07692 42.38462
## Disability  9.111111 12.77778 11.88889
## Radiation        NaN      NaN      NaN
## 
## , , Chain 2
## 
##                   1        2        3        4        5        6         7
## ID              NaN      NaN      NaN      NaN      NaN      NaN       NaN
## Pain            NaN      NaN      NaN      NaN      NaN      NaN       NaN
## Tampascale 40.76923 40.53846 39.92308 39.76923 41.53846 40.92308 40.538462
## Disability 11.44444 12.22222 13.66667 11.00000 10.22222 11.77778  9.666667
## Radiation       NaN      NaN      NaN      NaN      NaN      NaN       NaN
##                   8        9       10
## ID              NaN      NaN      NaN
## Pain            NaN      NaN      NaN
## Tampascale 39.53846 39.76923 40.53846
## Disability 11.44444 11.77778 13.00000
## Radiation       NaN      NaN      NaN
## 
## , , Chain 3
## 
##                    1        2        3        4         5        6
## ID               NaN      NaN      NaN      NaN       NaN      NaN
## Pain             NaN      NaN      NaN      NaN       NaN      NaN
## Tampascale 39.384615 39.69231 41.23077 40.69231 39.769231 40.76923
## Disability  9.333333 12.33333 11.55556 10.33333  9.555556 11.22222
## Radiation        NaN      NaN      NaN      NaN       NaN      NaN
##                   7        8        9        10
## ID              NaN      NaN      NaN       NaN
## Pain            NaN      NaN      NaN       NaN
## Tampascale 40.76923 41.61538 40.61538 40.307692
## Disability 11.66667 11.11111 11.44444  9.555556
## Radiation       NaN      NaN      NaN       NaN
## 
## , , Chain 4
## 
##                   1        2        3        4         5        6        7
## ID              NaN      NaN      NaN      NaN       NaN      NaN      NaN
## Pain            NaN      NaN      NaN      NaN       NaN      NaN      NaN
## Tampascale 39.76923 39.53846 40.15385 41.07692 40.076923 41.00000 39.84615
## Disability 11.44444 11.66667 10.55556 11.33333  9.222222 13.11111 14.22222
## Radiation       NaN      NaN      NaN      NaN       NaN      NaN      NaN
##                   8        9       10
## ID              NaN      NaN      NaN
## Pain            NaN      NaN      NaN
## Tampascale 40.84615 39.92308 41.15385
## Disability 11.00000 12.00000 12.11111
## Radiation       NaN      NaN      NaN
## 
## , , Chain 5
## 
##                   1        2        3        4        5        6        7
## ID              NaN      NaN      NaN      NaN      NaN      NaN      NaN
## Pain            NaN      NaN      NaN      NaN      NaN      NaN      NaN
## Tampascale 40.23077 40.30769 40.07692 40.00000 40.15385 41.00000 40.15385
## Disability 10.55556 10.11111 10.88889 12.77778 11.55556 11.66667 10.33333
## Radiation       NaN      NaN      NaN      NaN      NaN      NaN      NaN
##                   8        9       10
## ID              NaN      NaN      NaN
## Pain            NaN      NaN      NaN
## Tampascale 39.23077 41.46154 40.46154
## Disability 10.77778 10.00000 11.00000
## Radiation       NaN      NaN      NaN</code></pre>
</div>
<div id="checking-convergence-in-r" class="section level2">
<h2><span class="header-section-number">4.7</span> Checking Convergence in R</h2>
<p>When you use the mice function to create imputations it is a good idea to check if the imputation runs were successful and if you can thrust the imputations. This can be done by visualizing a convergence plot. On a convergence plot the means or standard deviations within imputation chains can be plotted, this can be done by presenting the information under the object LBP_imp$chainMean at the y-axis and the iterations on the x-axis. The convergence plot of the imputations from the imputations of R code 4.5 is presented in Figure 4.3 (we used 50 iterations to create the plot). In this plot you see that the variance between the imputation chains is almost equally large as that within the chains. If this is the case than there is healthy convergence. To create a convergence plot for only the Tampascale variable just use:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(imp)</code></pre></div>
<p><img src="Book_MI_files/figure-html/unnamed-chunk-77-1.png" width="672" /></p>
</div>
<div id="imputation-diagnostics-in-r" class="section level2">
<h2><span class="header-section-number">4.8</span> Imputation diagnostics in R</h2>
<p>It can also be of interest to compare the values that are imputed with those that are observed. For that, the stripplot function can be used in mice. This function can easily be used in combination with the mice function (R code 4.10). With this function it is possible to plot the observed and imputed values in one plot. An example is given in Figure 4.4. By comparing the observed and the imputed data points we get an idea if the imputed values can be thrusted. If there are no large differences between the imputed and observed values under MAR than we can conclude the imputed values are correct.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">stripplot</span>(imp)</code></pre></div>
<p><img src="Book_MI_files/figure-html/unnamed-chunk-78-1.png" width="672" /></p>
</div>
<div id="multiple-imputation-in-spss" class="section level2">
<h2><span class="header-section-number">4.9</span> Multiple imputation in SPSS</h2>
<p>The multiple imputation procedure in SPSS is based on the MICE algorithm that was developed in R. It is therefore no surprise that the settings of the mice function in R, are almost all covered by the options in SPSS. In SPSS these settings are presented in Window menu’s. Before you start the MI procedure it is important to set the measurement level of the variables with missing data in the Variable View window of your data. They are important for the regression model that is used to estimate the missing values in that variable. For example, if you define a variable as scale, then linear regression models are used, for categorical variables, logistic regression models are used.</p>
<div id="the-setting-for-multiple-imputation-in-spss" class="section level3">
<h3><span class="header-section-number">4.9.1</span> The setting for multiple imputation in SPSS</h3>
<p>Before we start the multiple imputation procedure, we set the starting point of the random number generator in SPSS at the fixed value of 950 (in R we use the seed for this). In this way we are able to reproduce our results. This fixing of starting values for the random number generator is in general not advisable, we use it here for educational purposes.</p>
<p>We set the random number generator in SPSS via</p>
<blockquote>
<p>Transform -&gt; Random Number Generators -&gt; Set Starting point -&gt; Fixed Value</p>
</blockquote>
<div class="figure" style="text-align: center"><span id="fig:fig4-5"></span>
<img src="images/fig4.5.png" alt="Set the Random Number Generator " width="90%" />
<p class="caption">
Figure 4.1: Set the Random Number Generator
</p>
</div>
<p>The multiple imputation procedure in SPSS can be started via</p>
<blockquote>
<p>Analyze -&gt; Multiple Imputation -&gt; Impute Missing Data Values.</p>
</blockquote>
<div class="figure" style="text-align: center"><span id="fig:fig4-6"></span>
<img src="images/fig4.6.png" alt="The variables Tab" width="90%" />
<p class="caption">
Figure 4.2: The variables Tab
</p>
</div>
<p>In the Variables tab the variables that are part of the imputation model have to be transported to the window “Variables in Model”. The variables are imputed sequentially in the order in which they are listed in the variables list. These variables are in our example the Pain, Tampascale, Disability and Radiation variables. Further, the number of imputed datasets can be defined as well as the dataset to which the imputed data values are saved. We choose for 5 imputations and call the dataset in which the imputed values will be stored “LBP_Imp”. In the Methods Tab the imputation method is defined.</p>
<div class="figure" style="text-align: center"><span id="fig:fig4-7"></span>
<img src="images/fig4.7.png" alt="The Methods Tab" width="90%" />
<p class="caption">
Figure 4.3: The Methods Tab
</p>
</div>
<p>In the Method tab we choose for a “Custom” under Imputation Method and for Fully conditional specification. The Fully Conditional Specification (FCS) procedure is the Bayesian sequential regression imputation method as explained in <em>section 4.3 and 4.4</em>. Under Model type for scale (continuous) variables we choose for Predictive Mean Matching. This procedure was explained in <em>section 3.7</em>. In the MICE package PMM is the default procedure for continuous variables with missing data. In SPSS the default is the linear regression procedure. In the Constraints Tab the options per variable are defined.</p>
<div class="figure" style="text-align: center"><span id="fig:fig4-8"></span>
<img src="images/fig4.8.png" alt="The Constraints Tab" width="90%" />
<p class="caption">
Figure 4.4: The Constraints Tab
</p>
</div>
<p>In the Constraints tab the role of a variable during the imputation process is defined and it is possible to restrict the range of imputed values of a scale variable. In addition, you can restrict the analysis to variables with less than a maximum percentage of missing values. When the PMM method is selected in the Method Tab, the Constraints tab can be skipped. The Constraints tab can be useful when the Linear Regression method is selected in the Method Tab <em>(see Appendix XX)</em>. Finally, in the Output Tab the generated output can be defined.</p>
<div class="figure" style="text-align: center"><span id="fig:fig4-9"></span>
<img src="images/fig4.9.png" alt="The Output Tab" width="90%" />
<p class="caption">
Figure 4.5: The Output Tab
</p>
</div>
<p>Display the Imputation model and the Descriptive statistics for variables with imputed values options can be selected for information about the imputation. When the FCS imputation method is used, you can request a dataset that contains iteration history data for FCS imputation. In our example this iteration history information is stored in the dataset “Iter_Backpain”. The dataset contains means and standard deviations by iteration for each scale variable for which values are imputed. You can plot the data to help assess model convergence <em>paragraph 4.9</em>.</p>
</div>
<div id="the-output-for-multiple-imputation-in-spss" class="section level3">
<h3><span class="header-section-number">4.9.2</span> The output for Multiple imputation in SPSS</h3>
<p>After the multiple imputation procedure is done, a new data window opens that contains the imputed datasets. These multiple imputed datasets are stacked on top of each other. In this file the imputed values are marked yellow. There is also an extra variable added to the file which is called <code>Imputation_</code> (Figure <a href="multiple-imputation.html#fig:fig4-10">4.6</a>). The imputed values can be marked and unmarked via &gt; View -&gt; Mark Imputed data</p>
<p>If you switch this possibility on, SPSS automatically recognizes the dataset as a multiple imputed dataset. If you switch this possibility off, SPSS treats the dataset as one dataset. This marking and unmarking can also be done in the Data view window via the button with yellow and white squares on the right site above (Figure <a href="multiple-imputation.html#fig:fig4-11">4.7</a>). If you click the button, a selection box appears with “Original data” selected,where you can easily move to the different imputed datasets. The variable <code>Imputation_</code> is a variable with a nominal measure. You can compare the use of this variable with the Split File option in SPSS where all analyses are done separately for the categories of the variable use to split the analyses. The difference is that with the <code>Imputation_</code> variable you also obtain pooled estimates for the statistical analyses.</p>
<div class="figure" style="text-align: center"><span id="fig:fig4-10"></span>
<img src="images/fig4.10.png" alt="Example of Multiple Imputed dataset" width="90%" />
<p class="caption">
Figure 4.6: Example of Multiple Imputed dataset
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:fig4-11"></span>
<img src="images/fig4.11.png" alt="Button and selection box to mark imputed values" width="90%" />
<p class="caption">
Figure 4.7: Button and selection box to mark imputed values
</p>
</div>
<p>The iteration history is stored in the Iter_Backpain dataset as we defined in the Output window. In this dataset the means and standard deviations of the imputed values at each iteration are stored. These values can be used to construct Convergence plots. More about making convergence plots will be discussed in the next paragraph.</p>
<div class="figure" style="text-align: center"><span id="fig:fig4-12"></span>
<img src="images/fig4.12.png" alt="The iteration history data" width="90%" />
<p class="caption">
Figure 4.8: The iteration history data
</p>
</div>
<p>Based on our settings, SPSS produces the following results in the output window. In the Imputation Specifications table, information is provided on the imputation method used, the number of imputations, the model used for the scale variables, if interactions were included in the imputation models, the setting for the maximum percentage of missing values and the setting for the maximum number of parameters in the imputation model (Figure <a href="multiple-imputation.html#fig:tab4-4">4.9</a>).</p>
<div class="figure" style="text-align: center"><span id="fig:tab4-4"></span>
<img src="images/tab4.4.png" alt="Imputation Specifications table" width="90%" />
<p class="caption">
Figure 4.9: Imputation Specifications table
</p>
</div>
<p>A second table, called Imputation Results, is presented with information about the imputation method, the number of fully conditional specification methods, the variables that are imputed and not imputed and the imputation sequence(Figure <a href="multiple-imputation.html#fig:tab4-5">4.10</a>).</p>
<div class="figure" style="text-align: center"><span id="fig:tab4-5"></span>
<img src="images/tab4.5.png" alt="Imputation Results" width="90%" />
<p class="caption">
Figure 4.10: Imputation Results
</p>
</div>
<p>The Imputation Models table presents information about the imputation models used for the variables with missing data (Figure <a href="multiple-imputation.html#fig:tab4-6">4.11</a>). Information is provided about the method of imputation, under the type column, the effect estimates used to impute the missing values, the number of missing and imputed values. For example for the Tampascale variable 13 values were missing and m=5 times 13 is 65 values were imputed.</p>
<div class="figure" style="text-align: center"><span id="fig:tab4-6"></span>
<img src="images/tab4.6.png" alt="Imputation Models" width="90%" />
<p class="caption">
Figure 4.11: Imputation Models
</p>
</div>
<p>The Descriptive statistics displaye the descriptive information of the original, imputed and completed data of the Tampascale and the Disability variable. In this way you can compare the completed data after MI with the original data.</p>
<div class="figure" style="text-align: center"><span id="fig:tab4-7"></span>
<img src="images/tab4.7.png" alt="Descriptive statistics" width="90%" />
<p class="caption">
Figure 4.12: Descriptive statistics
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:tab4-7"></span>
<img src="images/tab4.8.png" alt="Descriptive statistics" width="90%" />
<p class="caption">
Figure 4.12: Descriptive statistics
</p>
</div>
</div>
<div id="checking-convergence-after-multiple-imputation-in-spss" class="section level3">
<h3><span class="header-section-number">4.9.3</span> Checking Convergence after Multiple imputation in SPSS</h3>
<p>The dataset Iter_Backpain in the previous paragraph contains the means and standard deviations of the imputed values at each iteration and imputation round. This information is similar as the information in <code>imp$chainMean</code> in R. This dataset can be used to generate convergence plots, to check if the imputed values have the expected variation between the iterations.The iteration can be checked for the means and standard deviations seperately. In order to obtain seperate plots for htese summary statistics, the split file option in SPSS can be activated.</p>
<div class="figure" style="text-align: center"><span id="fig:fig4-17"></span>
<img src="images/fig4.17.png" alt="Split file" width="90%" />
<p class="caption">
Figure 4.13: Split file
</p>
</div>
<p>After activation of the split file option, the Graph menu in SPSS can be used to make the plots.</p>
<blockquote>
<p>Graph -&gt; Char Builder.</p>
</blockquote>
<div class="figure" style="text-align: center"><span id="fig:fig4-13"></span>
<img src="images/fig4.13.png" alt="Graph menu" width="90%" />
<p class="caption">
Figure 4.14: Graph menu
</p>
</div>
<p>Two windows will open that can be used to build a chart:</p>
<div class="figure" style="text-align: center"><span id="fig:fig4-14"></span>
<img src="images/fig4.14.png" alt="Chart Builder" width="90%" />
<p class="caption">
Figure 4.15: Chart Builder
</p>
</div>
<p>On the x-axis the put the <code>iteration number</code> variable and on the y-axis the variable for which we want to display the iteration history. The <code>Imputation Number</code> variable is dragged to the <code>set color</code> top-right.</p>
<div class="figure" style="text-align: center"><span id="fig:fig4-15"></span>
<img src="images/fig4.15.png" alt="Chart Builder" width="90%" />
<p class="caption">
Figure 4.16: Chart Builder
</p>
</div>
<p>As a result two plots appear with the iteation history for each imputation run.</p>
<div class="figure" style="text-align: center"><span id="fig:fig4-18"></span>
<img src="images/fig4.18.png" alt="Convergence plots" width="90%" />
<p class="caption">
Figure 4.17: Convergence plots
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:fig4-18"></span>
<img src="images/fig4.19.png" alt="Convergence plots" width="90%" />
<p class="caption">
Figure 4.17: Convergence plots
</p>
</div>
</div>
</div>
<div id="number-of-imputed-datasets-and-iterations" class="section level2">
<h2><span class="header-section-number">4.10</span> Number of Imputed datasets and iterations</h2>
<p>Researchers assume that the number of imputations needed to generate valid imputations has to be set at 3-5 imputations. This idea was based on the work of Rubin (1987). He showed that the precision of a pooled parameter becomes lower when a finite number of multiply imputed datasets is used compared to an infinite number (finite means a limited number of imputed datasets, like 5 imputed datasets and infinite means unlimited). The precision of a parameter is often represented by the sampling variance (or standard error (SE) estimate; the sampling variance is equal to SE2) of for example a regression coefficient. In case of multiple imputed datasets precision is determined by the pooled sampling variance or pooled SE. A measure to value the amount of precision (i.e. between the pooled sampling variance estimated in a finite compared to an infinite number of imputed datasets) is the relative efficiency (RE). The RE will be low when the number of imputations is high (and the precision becomes larger) and is defined as:</p>
<p>Formula 4.1</p>
<p>RE= 1/(1+ FMI/m)</p>
<p>FMI is the fraction of missing information and m is the number of imputed datasets. Where FMI is roughly equal to the percentage of missing data in the simplest case of one variable with missing data. When there are more variables in the imputation model, and these variables are correlated with the variables with missing data the FMI becomes lower (see paragraph 5.2 for more information about the FMI).</p>
<p>The relationship between the RE and the pooled sampling variance TPooled (or SE _Pooled^2) can also be written as (van Buuren 2012):</p>
<p>Formula 4.2:</p>
<p>T_(Pooled,finite)=RE×T_(Pooled,infinite)</p>
<p>which is equal to,</p>
<p>Formula 4.3:</p>
<p>Formula’s 4.2 and 4.3 can be interpreted as follows: if the RE is 0.93 or 93% (when for example FMI=0.4 and m=5), formula 4.2 becomes:</p>
<p>T_(Pooled,finite)=0.93×T_(Pooled,infinite),</p>
<p>This is the same as saying that the SE when 5 imputed datasets are used is sqrt0.93=0.96 times as large as the SE when an infinite number of imputed datasets will be used (the SE is the squared sampling variance, taking the square root of the sampling variance gives the SE). Because the RE is divided by 1, this is the same as saying that the SE when 5 imputed datasets are used is 1/sqrt0.93=1.04 times larger (or 4%) as the SE when an infinite number of imputed datasets will be used. Graham (2007) also studied the loss in power when infinite numbers of imputed datasets are used. They recommended that at least 20 imputed datasets are needed to restrict the loss of power when testing a relationship between variables. Bodner (2008) proposed the following guidelines after a simulation study using different values for the FMI to determine the number of imputed datasets. For FMI´s of 0.05, 0.1, 0.2, 0.3, 0.5 the following number of imputed dataets are needed: &gt; 3, 6, 12, 24, 59 respectively. Following the study of Bodner (2008), White et al. (2010), proposed a rule of thumb, based on the idea that the FMI is frequently lower than the percentage of missing cases. Their rule of thumb states that the number of imputed datasets should be at least equal to the percentage of missing cases. This means that when 10% is missing, 10 datasets should be generated, with 20% missing cases, 20 datasets, etc.</p>
<p>Iterations Van Buuren (2012) states that the number of iterations may depend on among others the correlation between variables and the percentage of missing data in variables. He proposed that a number of 5-20 iterations is enough to reach convergence. This number may be adjusted when the percentage of missing data is high. Nowadays computers are fast so that a higher number of iterations can easily be used.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="single-missing-data-imputations.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="data-analysis-after-multiple-imputation.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": ["Book_MI.pdf", "Book_MI.epub"],
"toc": {
"collapse": "subsection"
},
"split_by": "section"
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
