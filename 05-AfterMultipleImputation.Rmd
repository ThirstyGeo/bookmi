---
output:
  pdf_document: default
  html_document: default
---
# Data analysis after Multiple Imputation

In the previous Chapter we discussed multiple imputation (MI) and how imputations in multiple datasets are generated. After the imputations have been generated, the data analysis and pooling steps follow. This chapter explains these steps. In the data analysis step, the statistical model is applied in the imputed datasets. In the pooling step, the analysis results from the analysis step, are summarized into one final result. The biggest challenge is to summarize the statistical results into one estimate with the related pooled standard errors, confidence intervals and a pooled p-value. Rubin (1987) provided rules which can be applied to many different statistical tests. Rubin´s rules are not available for all statistical procedures in SPSS. Many test procedures that do not have pooling results not available in SPSS are available in R. 
	We will start this Chapter with an example of applying t-tests in multiple imputed datasets. With this procedure we can explain the use of Rubin´s Rules (RR), and the derivation of the degrees of freedom for hypothesis testing, which can become complex. We will further discuss missing data measures that are derived from RR, such as the fraction of missing information (FMI), the relative increase in variance due to missing data (Relative Increase Variance) and Relative Efficiency. We will further show other pooling procedures for frequently used statistical techniques and how to apply them in multiply imputed datasets. The availability of each method in SPSS and R, are discussed and their application is presented. Specific pooling methods that are not available in SPSS are discussed by using examples in R.

## Rubin´s Rules – A first example

Rubin proposed methods to combine statistical test results into one (pooled) summary estimate. These so-called Rubin´s Rules (RR) are designed to pool parameter estimates, such as means differences and regression coefficients, standard errors and to derive confidence intervals and p-values. T-tests are frequently used and suitable to discuss all aspects of using RR, from pooling parameter estimates to deriving degrees of freedom and p-values. We will first illustrate the use of RR with a t-test example in 3 generated multiple imputed datasets in SPSS. In this example we will pool the mean differences and standard errors. The derivation of the test statistic t for hypothesis testing, degrees of freedom and p-value may differ between the statistical method used. These derivations are explained but also discussed in more detail. As an illustration, we use de LBP study again, and test the Tampascale mean difference (dependent variable) between backpain patients with and without radiation in the leg (dependent variable). The output of the t-test in the multiple imputed data can be found in Table 5.1.

```{r fig5_1, echo = FALSE, fig.cap="T-test for difference in mean Tampascale values between patients with and without Radiation in the leg applied in multiple imputed datasets.", out.width='90%', fig.align='center'}
knitr::include_graphics("images/table5.1.png")
```

```{r fig5_1b, echo = FALSE, fig.cap="T-test for difference in mean Tampascale values between patients with and without Radiation in the leg applied in multiple imputed datasets.", out.width='90%', fig.align='center'}
knitr::include_graphics("images/table5.1b.png")
```

In Table 5.1 the relationship in the original dataset is presented in the row that is indicated by Imputation_ number 0 as well as in each imputed dataset which are indicated by Imputation_ number 1 to 3. In the last row which is indicated as “Pooled”, the summary estimates of the parameters are presented. With parameters we mean the parameters of interest which are here the mean differences and standard errors. We will explain now by using RR how these pooled mean differences and standard errors are estimated.

### Pooling Parameters

When RR are used, it is assumed that the repeated parameter estimates in each imputed dataset (e.g. mean differences), are normally distributed. This cannot be assumed for all statistical test statistics, e.g. correlation coefficients. For these test statistics, transformations have to be performed before RR can be applied to assume normality (will be discussed below).  To illustrate the use of RR, we start with the T-test example of Table 5.1 

To calculate the pooled parameter estimate the following formula is used:

$$\bar{x}$$



